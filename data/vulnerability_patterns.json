{
  "patterns": {
    "00a63ad01c0055a0": {
      "pattern_id": "00a63ad01c0055a0",
      "category": "logic_flaw",
      "name": "Timestamp parsing logic is broken",
      "description": "The get_stats() method has a flawed datetime parsing approach that silently corrupts data. The line `datetime.fromisoformat(m.timestamp.replace(\"Z\", \"+00:00\").replace(\"+00:00\", \"\"))` first replaces Z with +00:00, THEN immediately replaces +00:00 with empty string, resulting in an invalid ISO format string. For timestamp '2024-01-01T10:00:00Z', this becomes '2024-01-01T10:00:00' which loses timezone info. More critically, this will crash if the timestamp is already in a different format.",
      "code_pattern": "WebVitalsCollector.get_stats:176-177",
      "example_code": "Call record_from_dict with timestamp='2024-01-01T10:00:00Z'",
      "fix_guidance": "Use proper timezone-aware parsing: `datetime.fromisoformat(m.timestamp.replace('Z', '+00:00'))` without the second replace. Or better: use `datetime.fromisoformat(m.timestamp.replace('Z', '+00:00').split('+')[0])` to strip timezone after parsing, or use a proper ISO 8601 parser.",
      "severity_typical": "critical",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.761697",
      "last_seen": "2025-12-16T20:09:16.761697",
      "tags": [
        "logic_flaw"
      ]
    },
    "d317651e86ab8284": {
      "pattern_id": "d317651e86ab8284",
      "category": "error_handling",
      "name": "Silent exception swallowing in batch endpoint",
      "description": "The /api/vitals/batch endpoint catches all exceptions with bare `except Exception: pass`, meaning invalid or malicious measurements are silently dropped. An attacker can send crafted JSON that will fail to process but the endpoint returns 200 OK claiming success. This makes it impossible to debug or detect issues. Additionally, this hides programming errors during development.",
      "code_pattern": "WebVitalsAPI.record_vitals_batch:290-295",
      "example_code": "POST to /api/vitals/batch with [{\"name\": \"LCP\", \"value\": \"not_a_number\"}]",
      "fix_guidance": "Log exceptions or return them in the response. At minimum: `except (ValueError, KeyError) as e: logger.error(f'Failed to record measurement: {e}')`. Or return partial failure info: track which items succeeded/failed and return a 207 Multi-Status response.",
      "severity_typical": "high",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.762015",
      "last_seen": "2025-12-16T20:09:16.762015",
      "tags": [
        "error_handling"
      ]
    },
    "12fd28e4869a401b": {
      "pattern_id": "12fd28e4869a401b",
      "category": "type_confusion",
      "name": "Unvalidated type coercion allows injection of any value into 'value' field",
      "description": "The record_from_dict() method blindly converts data['value'] to float with `float(data.get('value', 0))`. This will accept strings like 'inf', '-inf', 'nan', or numbers like 1e308 which could break statistics calculations. `statistics.median()`, `statistics.mean()`, and `statistics.quantiles()` will fail or produce invalid results when given NaN or infinity values.",
      "code_pattern": "WebVitalsCollector.record_from_dict:130",
      "example_code": "Call record_from_dict({'name': 'LCP', 'value': 'inf'})",
      "fix_guidance": "Validate the value: `value = float(data.get('value', 0)); assert not math.isnan(value) and not math.isinf(value) and value >= 0, 'Invalid metric value'`. Or use a schema validator like Pydantic.",
      "severity_typical": "high",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.762325",
      "last_seen": "2025-12-16T20:09:16.762325",
      "tags": [
        "type_confusion"
      ]
    },
    "d85e98830268adb5": {
      "pattern_id": "d85e98830268adb5",
      "category": "boundary",
      "name": "Negative values not validated",
      "description": "Web Vitals metrics should never be negative (they're measurements in milliseconds), but the code accepts and stores negative values. Calling get_stats() with negative values will produce nonsensical statistics (min could be -infinity, mean could be negative).",
      "code_pattern": "WebVitalsCollector.record_from_dict:130",
      "example_code": "Call record_from_dict({'name': 'LCP', 'value': -5000})",
      "fix_guidance": "Add validation: `if value < 0: raise ValueError(f'Metric value cannot be negative: {value}')`",
      "severity_typical": "high",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.762653",
      "last_seen": "2025-12-16T20:09:16.762653",
      "tags": [
        "boundary"
      ]
    },
    "8010c505617aa5f6": {
      "pattern_id": "8010c505617aa5f6",
      "category": "boundary",
      "name": "Unbounded metric values accepted",
      "description": "The code accepts arbitrarily large metric values (1e308, 1e1000, etc). While float() will clamp to infinity, this allows injection of malicious data that could skew statistics or be used as a denial-of-service attack by sending millions of huge values that fill memory.",
      "code_pattern": "WebVitalsCollector.record_from_dict:130",
      "example_code": "POST 1000 measurements with value=1e308 to /api/vitals/batch",
      "fix_guidance": "Add bounds checking: `if value > 1_000_000: raise ValueError(f'Metric value too large: {value}')`. Set reasonable max values like 60000ms for LCP, 1000ms for FID, etc.",
      "severity_typical": "high",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.763043",
      "last_seen": "2025-12-16T20:09:16.763043",
      "tags": [
        "boundary"
      ]
    },
    "a5e67939b6fc949a": {
      "pattern_id": "a5e67939b6fc949a",
      "category": "concurrency",
      "name": "TOCTOU race condition in cache validation",
      "description": "In get_stats(), the cache check is not atomic with the cache write. Between checking `(now - self._cache_time) < self._cache_ttl` and the subsequent `with self._lock`, another thread could invalidate the cache by calling record(). Also, the cache is checked BEFORE acquiring the lock, so multiple threads could all see cache miss and compute stats simultaneously.",
      "code_pattern": "WebVitalsCollector.get_stats:162-170",
      "example_code": "Thread A calls get_stats(), passes cache check (hits if statement)",
      "fix_guidance": "Move cache check inside the lock: `with self._lock: if self._cache_time and ... return self._stats_cache`. Or use a RLock with the check-then-update atomic.",
      "severity_typical": "high",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.763482",
      "last_seen": "2025-12-16T20:09:16.763482",
      "tags": [
        "concurrency"
      ]
    },
    "00daa4ad08dfc7d1": {
      "pattern_id": "00daa4ad08dfc7d1",
      "category": "logic_flaw",
      "name": "Quantiles calculation crashes on small datasets",
      "description": "The code checks `len(values) >= 4` and `len(values) >= 20` but `statistics.quantiles()` will raise ValueError if called with n=4 on a list with fewer than 5 elements, or n=20 on fewer than 21 elements. The boundary check is off-by-one. Also, if len(values)==1, calling max(values) when quantiles fails is fine, but the logic is unclear.",
      "code_pattern": "WebVitalsCollector.get_stats:192-195",
      "example_code": "Record 4 LCP measurements",
      "fix_guidance": "Change to: `'p75': statistics.quantiles(values, n=4)[2] if len(values) > 4 else max(values)` and `'p95': statistics.quantiles(values, n=20)[18] if len(values) > 20 else max(values)`",
      "severity_typical": "high",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.763990",
      "last_seen": "2025-12-16T20:09:16.763990",
      "tags": [
        "logic_flaw"
      ]
    },
    "519c80dd26fc292d": {
      "pattern_id": "519c80dd26fc292d",
      "category": "boundary",
      "name": "get_recent_measurements limit parameter unbounded on Python side",
      "description": "Although the Flask route limits the limit to 200, if someone calls collector.get_recent_measurements(1_000_000) directly, it will return a huge list. The deque only holds max_measurements, but still this could consume significant memory/network if the Flask clamping is bypassed.",
      "code_pattern": "WebVitalsCollector.get_recent_measurements:238",
      "example_code": "Directly call collector.get_recent_measurements(999999)",
      "fix_guidance": "Add bounds checking in the method itself: `limit = min(limit, 500)` at the start of the function.",
      "severity_typical": "medium",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.764537",
      "last_seen": "2025-12-16T20:09:16.764537",
      "tags": [
        "boundary"
      ]
    },
    "de6c7ed0ad539a54": {
      "pattern_id": "de6c7ed0ad539a54",
      "category": "logic_flaw",
      "name": "Cache key doesn't include retention_hours",
      "description": "The cache is keyed only on `hours` parameter, but get_stats() also depends on `retention_hours` and the current time window. If you call get_stats(hours=24) multiple times over a span longer than retention_hours, the cache will return old, expired data because it doesn't account for data being purged.",
      "code_pattern": "WebVitalsCollector.get_stats:168",
      "example_code": "Call get_stats(hours=1) at T=0, get 100 measurements",
      "fix_guidance": "Add current time to cache key: `if self._stats_cache.get('timestamp_key') == str(now.date())` or include data age in validation.",
      "severity_typical": "medium",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.765134",
      "last_seen": "2025-12-16T20:09:16.765134",
      "tags": [
        "logic_flaw"
      ]
    },
    "6b44c0b38a271e2e": {
      "pattern_id": "6b44c0b38a271e2e",
      "category": "injection",
      "name": "Unescaped string interpolation in error responses",
      "description": "In WebVitalsAPI.record_vital(), the code returns `jsonify({'error': str(e)})`. If an exception message contains user input data, it could be returned in the JSON response. While not XSS (it's JSON), it could leak internal data or exception chains.",
      "code_pattern": "WebVitalsAPI.record_vital:283",
      "example_code": "POST with malformed JSON that includes a file path in error message",
      "fix_guidance": "Return generic error messages: `return jsonify({'error': 'Invalid measurement data'}), 400` and log the actual exception server-side.",
      "severity_typical": "high",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.765777",
      "last_seen": "2025-12-16T20:09:16.765777",
      "tags": [
        "injection"
      ]
    },
    "72098b1f14272acb": {
      "pattern_id": "72098b1f14272acb",
      "category": "state_corruption",
      "name": "Rating enum value inconsistency",
      "description": "The code uses `VitalRating.GOOD.value` which returns string 'good', but also has hardcoded strings like 'needs-improvement' and 'poor' throughout. If someone changes the enum values, the hardcoded strings won't match. The _get_rating() default return is NEEDS_IMPROVEMENT.value but could be inconsistent with comparisons.",
      "code_pattern": "VitalRating enum and multiple references",
      "example_code": "Change VitalRating.GOOD = 'excellent'",
      "fix_guidance": "Use enum values consistently everywhere. Replace string literals with enum: `return VitalRating.NEEDS_IMPROVEMENT.value` only via enum.",
      "severity_typical": "medium",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.766478",
      "last_seen": "2025-12-16T20:09:16.766478",
      "tags": [
        "state_corruption"
      ]
    },
    "63c4115c6329889e": {
      "pattern_id": "63c4115c6329889e",
      "category": "boundary",
      "name": "Empty measurements list causes statistics to fail",
      "description": "If get_stats() is called when there are no measurements in the time window, the `by_vital` dict will be empty. The stats dict will have empty 'vitals' object, but then _calculate_score() will have no vitals to score, returning 0. This is correct behavior, but if someone tries to access stats['vitals']['LCP'] it will KeyError.",
      "code_pattern": "WebVitalsCollector.get_stats:186-204",
      "example_code": "Call get_stats() with hours=1 when no measurements exist",
      "fix_guidance": "Document that 'vitals' can be empty. Or initialize all vitals with zeros: `for name in ['LCP', 'FID', 'INP', 'CLS', 'TTFB', 'FCP']: if name not in stats['vitals']: stats['vitals'][name] = {...zeros...}`",
      "severity_typical": "medium",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.767460",
      "last_seen": "2025-12-16T20:09:16.767460",
      "tags": [
        "boundary"
      ]
    },
    "30dc286feb7d67bd": {
      "pattern_id": "30dc286feb7d67bd",
      "category": "logic_flaw",
      "name": "Timestamp default uses current time, not measurement time",
      "description": "In record_from_dict(), if no timestamp is provided, it defaults to `datetime.now().isoformat()`. This is the time the server recorded it, not the client time. For a batch of measurements sent in one request, they'll all get the same server timestamp even if they occurred at different client times.",
      "code_pattern": "WebVitalsCollector.record_from_dict:137",
      "example_code": "Client collects LCP at T=0, FID at T=5, batches both, sends at T=10",
      "fix_guidance": "Require timestamp in the data: `timestamp = data.get('timestamp'); if not timestamp: raise ValueError('timestamp required')`. Or at least use a more accurate client-sent time.",
      "severity_typical": "medium",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.768317",
      "last_seen": "2025-12-16T20:09:16.768317",
      "tags": [
        "logic_flaw"
      ]
    },
    "bfd3a7f7f8af4f80": {
      "pattern_id": "bfd3a7f7f8af4f80",
      "category": "error_handling",
      "name": "JavaScript silently fails to send measurements",
      "description": "The JavaScript code catches all exceptions with `catch (e) {}` silently. If a PerformanceObserver fails to initialize, the measurement is never sent. Users will think vitals are being collected but nothing reaches the server.",
      "code_pattern": "WEB_VITALS_COLLECTOR_JS (multiple try/catch blocks)",
      "example_code": "Browser blocks PerformanceObserver API (privacy settings, older browser)",
      "fix_guidance": "Log errors to console: `catch (e) { console.warn('Failed to observe vitals:', e); }` or send error beacon.",
      "severity_typical": "medium",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.769195",
      "last_seen": "2025-12-16T20:09:16.769195",
      "tags": [
        "error_handling"
      ]
    },
    "da3c37672d2886b0": {
      "pattern_id": "da3c37672d2886b0",
      "category": "boundary",
      "name": "deque maxlen silently drops oldest data",
      "description": "The deque is initialized with maxlen=max_measurements (default 1000). When it fills up, appending a new item silently drops the oldest item. If someone is querying recent data and hasn't called get_stats() in a while, they might miss older measurements. This could be confusing - no error is raised.",
      "code_pattern": "WebVitalsCollector.__init__:113",
      "example_code": "Create WebVitalsCollector(max_measurements=100)",
      "fix_guidance": "Document this behavior clearly. Or track a 'total_recorded' counter and warn if querying beyond available data. Or raise an exception if limit > available.",
      "severity_typical": "medium",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.770105",
      "last_seen": "2025-12-16T20:09:16.770105",
      "tags": [
        "boundary"
      ]
    },
    "b8de870fccbaf819": {
      "pattern_id": "b8de870fccbaf819",
      "category": "resource_exhaustion",
      "name": "sendBeacon may not work with huge batch payloads",
      "description": "The JavaScript batches measurements and sends via navigator.sendBeacon(). Some browsers have size limits (typically 64KB) and sendBeacon silently fails if the payload is too large. The fallback fetch() has keepalive:true but could also fail.",
      "code_pattern": "WEB_VITALS_COLLECTOR_JS (flushQueue function)",
      "example_code": "Collect 10000 measurements in a batch",
      "fix_guidance": "Check payload size before sending. Split large batches. Return error from sendBeacon and retry.",
      "severity_typical": "medium",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.771083",
      "last_seen": "2025-12-16T20:09:16.771083",
      "tags": [
        "resource_exhaustion"
      ]
    },
    "1c8b875cc76f45ad": {
      "pattern_id": "1c8b875cc76f45ad",
      "category": "type_confusion",
      "name": "Device_type case sensitivity issue",
      "description": "JavaScript sends device_type as 'mobile' or 'desktop' (lowercase), but the code doesn't normalize case. If client sends 'Mobile' or 'DESKTOP', it stores that variant. Aggregations by device_type might not match.",
      "code_pattern": "WebVitalsCollector.record_from_dict:139",
      "example_code": "Client sends device_type='Mobile'",
      "fix_guidance": "Normalize: `device_type=data.get('device_type', 'desktop').lower()`",
      "severity_typical": "medium",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.772123",
      "last_seen": "2025-12-16T20:09:16.772123",
      "tags": [
        "type_confusion"
      ]
    },
    "9d1cf5c7f7d50509": {
      "pattern_id": "9d1cf5c7f7d50509",
      "category": "logic_flaw",
      "name": "Connection type 'unknown' can't be filtered",
      "description": "If navigator.connection is not available, JavaScript sends connection_type='unknown'. This could be a large portion of measurements in some browsers. Stats aggregations can't distinguish real network conditions from missing data.",
      "code_pattern": "WEB_VITALS_COLLECTOR_JS (sendMeasurement function)",
      "example_code": "Mobile browser without navigator.connection API",
      "fix_guidance": "Only send connection_type if available, use null/empty string otherwise. Or document that 'unknown' is a valid value.",
      "severity_typical": "low",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.773213",
      "last_seen": "2025-12-16T20:09:16.773213",
      "tags": [
        "logic_flaw"
      ]
    },
    "5220878edd3edaad": {
      "pattern_id": "5220878edd3edaad",
      "category": "logic_flaw",
      "name": "Duplicate CLS measurement on visibility change",
      "description": "The CLS observer uses `observe({ buffered: true })` which captures historical data, but then sends CLS again on page hide. If there are multiple page hide events (rare but possible), CLS could be sent multiple times.",
      "code_pattern": "WEB_VITALS_COLLECTOR_JS (CLS observer)",
      "example_code": "Trigger multiple visibilitychange events",
      "fix_guidance": "Add a flag to ensure CLS is only sent once: `let clsSent = false; ... if (!clsSent) { sendMeasurement(...); clsSent = true; }`",
      "severity_typical": "low",
      "occurrences": 1,
      "missions_found_in": [
        "mission_865ac720"
      ],
      "first_seen": "2025-12-16T20:09:16.774299",
      "last_seen": "2025-12-16T20:09:16.774299",
      "tags": [
        "logic_flaw"
      ]
    }
  },
  "mission_records": {
    "mission_865ac720": {
      "mission_id": "mission_865ac720",
      "timestamp": "2025-12-16T20:09:16.775507",
      "code_path": "/home/vader/mini-mind-v2/missions/mission_865ac720/workspace/performance/web_vitals.py",
      "patterns_found": [
        "00a63ad01c0055a0",
        "d317651e86ab8284",
        "12fd28e4869a401b",
        "d85e98830268adb5",
        "8010c505617aa5f6",
        "a5e67939b6fc949a",
        "00daa4ad08dfc7d1",
        "519c80dd26fc292d",
        "de6c7ed0ad539a54",
        "6b44c0b38a271e2e",
        "72098b1f14272acb",
        "63c4115c6329889e",
        "30dc286feb7d67bd",
        "bfd3a7f7f8af4f80",
        "da3c37672d2886b0",
        "b8de870fccbaf819",
        "1c8b875cc76f45ad",
        "9d1cf5c7f7d50509",
        "5220878edd3edaad"
      ],
      "findings_count": 19,
      "critical_count": 1,
      "high_count": 7,
      "medium_count": 9,
      "low_count": 2
    }
  },
  "stats": {
    "total_findings": 19,
    "total_missions": 0,
    "by_category": {
      "logic_flaw": 6,
      "error_handling": 2,
      "type_confusion": 2,
      "boundary": 5,
      "concurrency": 1,
      "injection": 1,
      "state_corruption": 1,
      "resource_exhaustion": 1
    },
    "by_severity": {
      "critical": 1,
      "high": 7,
      "medium": 9,
      "low": 2
    }
  },
  "last_updated": "2025-12-16T20:09:16.775851"
}